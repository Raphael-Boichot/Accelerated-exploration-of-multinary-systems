{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480028fe",
   "metadata": {},
   "source": [
    "# **PyTerK** - A Python Iterated K-fold cross validation with shuffling  \n",
    "----\n",
    "\n",
    "## Example 5 - combinational_iterative_manyfold() - Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b4ceb",
   "metadata": {},
   "source": [
    "## Step 1 - Init python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad6641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import os\n",
    "import pyterk.config       as config\n",
    "import pyterk.task_manager as task_manager\n",
    "import pyterk.reporter     as reporter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f9673a",
   "metadata": {},
   "source": [
    "## Step 2 - Load settings\n",
    "Settings are in a usefull and human readable yaml format :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b941995",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = config.load('settings_example.yml',\n",
    "                        datasets_dir_env='undef', run_dir_env='undef')\n",
    "\n",
    "run_dir  = config.run_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bf9fcd",
   "metadata": {},
   "source": [
    "## Step 3 - Add combinational iterative manyfold tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_manager.reset()\n",
    "task_manager.seed(settings)\n",
    "\n",
    "task_manager.add_combinational_iterative_manyfold(settings = settings, run_key= 'Example-05.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d37c5",
   "metadata": {},
   "source": [
    "## Step 4 - Run tasks\n",
    "On my laptop, with 8 cores : 26.96'  \n",
    "At GRICAD, with 32 cores : 7.02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b418865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To hide ugly warnings (triggered tf.function retracing...)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "task_manager.run(verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0d960a",
   "metadata": {},
   "source": [
    "## Step 5 - Plot Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter.plot_confusion(f'{run_dir}/Example-05.1/Example-05.1-0000', normalize='pred', figsize=(5,4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e93d9ba",
   "metadata": {},
   "source": [
    "## Step 6 - Show report, with confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebeeaa7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reporter.show_report(f'{run_dir}/Example-05.1', \n",
    "                        sections   = ['title','context','args','settings','evaluation', 'monitoring', 'history', 'distribution', 'confusion'],\n",
    "                        context    = ['function', 'version', 'date', 'description', 'seed'],\n",
    "                        args       = ['run_dir', 'dataset_id', 'model_id', 'n_iter', 'k_fold', 'epochs', 'batch_size'],\n",
    "                        settings   = ['file', 'version', 'description', 'datasets_dir', 'run_dir'],\n",
    "                        evaluation = ['all'],\n",
    "                        monitoring = ['duration', 'used_data'],\n",
    "                        history      = [ dict(metric='val_accuracy', min=None,max=None, figsize=(5,5), savefig=True, mplstyle='pyterk') ],\n",
    "                        distribution = [ dict(metric_id=0, bins=4,  min=None,max=None, figsize=(5,5), savefig=True, mplstyle='pyterk') ],\n",
    "                        correlation  = [ dict(axes_min='auto',axes_max='auto', figsize=(8,6), marker='.', markersize=8, alpha=0.7, color='auto', savefig=True, mplstyle='pyterk') ],\n",
    "                        confusion    = [ dict(normalize='pred', predict_type='softmax', figsize=(5,5), savefig=True, mplstyle='pyterk') ]\n",
    "                      \n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82c1b89",
   "metadata": {},
   "source": [
    "## Step 7 - Run reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab59594",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reporter.show_run_reports(  settings,\n",
    "                            run_filter='Example-05.*',\n",
    "                            sections   = ['title','context','args','settings','evaluation', 'monitoring', 'history', 'distribution', 'confusion'],\n",
    "                            context    = ['function', 'version', 'date', 'description', 'seed'],\n",
    "                            args       = ['run_dir', 'dataset_id', 'model_id', 'n_iter', 'k_fold', 'epochs', 'batch_size'],\n",
    "                            settings   = ['file', 'version', 'description', 'datasets_dir', 'run_dir'],\n",
    "                            evaluation = ['all'],\n",
    "                            monitoring = ['duration', 'used_data'],\n",
    "                            history      = [ dict(metric='val_accuracy', min=None,max=None, figsize=(5,5), savefig=True, mplstyle='pyterk') ],\n",
    "                            distribution = [ dict(metric_id=0, bins=4,  min=None,max=None, figsize=(5,5), savefig=True, mplstyle='pyterk') ],\n",
    "                            correlation  = [ dict(axes_min='auto',axes_max='auto', figsize=(8,6), marker='.', markersize=8, alpha=0.7, color='auto', savefig=True, mplstyle='pyterk') ],\n",
    "                            confusion    = [ dict(normalize='pred', predict_type='softmax', figsize=(5,5), savefig=True, mplstyle='pyterk') ]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb3d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df156f56",
   "metadata": {},
   "source": [
    "---\n",
    "### PyTerK 2021"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7822d55dc7294a4f6f06b86d8ad2ca65bd6e1ee5d72628c47c30a06bbf89aef6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
