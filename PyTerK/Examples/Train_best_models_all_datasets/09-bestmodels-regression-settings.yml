# ------------------------------------------------------------------
#                  ____        _            _
#                 |  _ \ _   _| |_ ___ _ __| | __
#                 | |_) | | | | __/ _ \ '__| |/ /
#                 |  __/| |_| | ||  __/ |  |   <
#                 |_|    \__, |\__\___|_|  |_|\_\
#                        |___/                        Settings file
# ------------------------------------------------------------------
# Python Iterator for Kfold and co. - pjluc 2021
#
# This is a sample configuration
# 
# Note : Afin d'être portable, le paramètre datasets_dir peut être
#        forcé via une variable d'environnement.

global:
    description: Best regression models of NN, RF, SVM with all datasets
    settings v.: 1.0
    seed: 123
    datasets_dir: ./
    run_dir: ./Train_model_regression

datasets:
    
    compo_E_w_outliers:
        filename: Raw_data_corrected.csv
        columns_x: ['Zr_at','Nb_at','Mo_at','Ti_at','Cr_at']
        columns_y: ['E (GPa)']
        
    compo_H_w_outliers:
        filename: Raw_data_corrected.csv
        columns_x: ['Zr_at','Nb_at','Mo_at','Ti_at','Cr_at']
        columns_y: ['H (GPa)']
        
        
    compo_E_threshold:
        filename: Compo_E_H_threshold.csv
        columns_x: ['Zr_at','Nb_at','Mo_at','Ti_at','Cr_at']
        columns_y: ['E (GPa)']
        
    compo_H_threshold:
        filename: Compo_E_H_threshold.csv
        columns_x: ['Zr_at','Nb_at','Mo_at','Ti_at','Cr_at']
        columns_y: ['H (GPa)']
        
    
    compo_E_wo_outliers:
        filename: Compo_E_wo_outlier.csv
        columns_x: ['Zr_at','Nb_at','Mo_at','Ti_at','Cr_at']
        columns_y: ['E (GPa)']
        
    compo_H_wo_outliers:
        filename: Compo_H_wo_outlier.csv
        columns_x: ['Zr_at','Nb_at','Mo_at','Ti_at','Cr_at']
        columns_y: ['H (GPa)']
        
        
    compo_E_wo_outliers_averaged:
        filename: Data_averaged.csv
        columns_x: ['Zr_at','Nb_at','Mo_at','Ti_at','Cr_at']
        columns_y: ['E (GPa)']
        
    compo_H_wo_outliers_averaged:
        filename: Data_averaged.csv
        columns_x: ['Zr_at','Nb_at','Mo_at','Ti_at','Cr_at']
        columns_y: ['H (GPa)']
        
    
    compo_CI:
        filename: Data_averaged.csv
        columns_x: ['Zr_at','Nb_at','Mo_at','Ti_at','Cr_at']
        columns_y: ['CI']
        
    compo_IQ:
        filename: Data_averaged.csv
        columns_x: ['Zr_at','Nb_at','Mo_at','Ti_at','Cr_at']
        columns_y: ['IQ']
    

        
models:
# Regression
    # RF fit E
    sklearn-RF-100-10:
        module: sklearn.ensemble
        class: RandomForestRegressor
        args: { 'n_estimators':100 , 'min_samples_split':10}

    # RF fit H     
    sklearn-rfr-150-10:
        module: sklearn.ensemble
        class: RandomForestRegressor
        args: { 'n_estimators':150 ,  'criterion':'mae', 'min_samples_split':10}

    # RF fit CI 
    sklearn-rfr-150-5:
        module: sklearn.ensemble
        class: RandomForestRegressor
        args: { 'n_estimators':150 ,'min_samples_split':5 } 

    # RF fit IQ
    sklearn-rfr-50-5:
        module: sklearn.ensemble
        class: RandomForestRegressor
        args: { 'n_estimators':50 ,'min_samples_split':5 } 

        
    # NN fit E, H, IQ 
    keras-100x100x100x100:
        module: my_models
        function: get_keras_mpp
        args: { 'input_shape':[5], 'neurons':[100,100,100,100,1], 'activations':['relu','relu','relu','relu',None], 'optimizer':'adam', 'loss':'mse', 'metrics':['mse','mae','mape'] }
        
    # NN fit CI 
    keras-50x100x100x50:
        module: my_models
        function: get_keras_mpp
        args: { 'input_shape':[5], 'neurons':[50,100,100,50,1], 'activations':['relu','relu','relu','relu',None], 'optimizer':'adam', 'loss':'mse', 'metrics':['mse','mae','mape'] }
        

    # SVM fit E, H        
    sklearn-nuSVR-rbf-0.5-1000:
        module: sklearn.svm
        class: NuSVR
        args: { 'kernel':'rbf', 'nu':0.5, 'C':1000}

    # SVM fit CI
    sklearn-nuSVR-rbf-0.8-100:
        module: sklearn.svm
        class: NuSVR
        args: { 'kernel':'rbf', 'nu':0.8, 'C':100}
    
    # SVM fit IQ
    sklearn-nuSVR-poly3-0.2-1000:
        module: sklearn.svm
        class: NuSVR
        args: { 'kernel':'poly', 'degree':3, 'nu':0.2, 'C':1000}



runs:

    Fit_E:
        description: Fit E on all dataset and all best models
        datasets: [ 'compo_E_w_outliers','compo_E_threshold','compo_E_wo_outliers','compo_E_wo_outliers_averaged']
        models: [ 'sklearn-RF-100-10','keras-100x100x100x100','sklearn-nuSVR-rbf-0.5-1000']
        n_iters: [ 30 ]
        k_folds: [ 5 ]
        epochs: [ 200 ]
        batch_sizes: [ 8 ]
        seed: 123
        save_yytest: True 
   
    Fit_H:
        description: Fit H on all dataset and all best models
        datasets: [ 'compo_H_w_outliers','compo_H_threshold','compo_H_wo_outliers','compo_H_wo_outliers_averaged']
        models:  [ 'sklearn-rfr-150-10','keras-100x100x100x100','sklearn-nuSVR-rbf-0.5-1000']
        n_iters: [ 30 ]
        k_folds: [ 5 ]
        epochs: [ 200 ]
        batch_sizes: [ 8 ]
        seed: 123
        save_yytest: True 
        
    Fit_CI:
        description: Comparison of architecture on CI
        datasets: [ 'compo_CI']
        models: [ 'sklearn-rfr-150-5','keras-50x100x100x50','sklearn-nuSVR-rbf-0.8-100']
        n_iters: [ 30 ]
        k_folds: [ 5 ]
        epochs: [ 200 ]
        batch_sizes: [ 8 ]
        seed: 123
        save_yytest: True 
    
    Fit_IQ:
        description: Comparison of architecture on IQ
        datasets: [ 'compo_IQ']
        models:  ['sklearn-rfr-50-5','keras-100x100x100x100','sklearn-nuSVR-poly3-0.2-1000']
        n_iters: [ 30 ]
        k_folds: [ 5 ]
        epochs: [ 200 ]
        batch_sizes: [ 8 ]
        seed: 123
        save_yytest: True 
        